{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "import shutil \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_structure(base_folder):\n",
    "    subfolders = {\n",
    "        \"piedata(1008)\": \"pie\",\n",
    "        \"linedata(1028)\": \"line\",\n",
    "        \"bardata(1031)\": \"bar\",\n",
    "        \"clsdata(1031)\": \"cls\"\n",
    "    }\n",
    "\n",
    "    sub_subfolders = [\"images\", \"annotations\"]\n",
    "\n",
    "    image_subfolders = [\"train2019\", \"test2019\", \"val2019\"]\n",
    "\n",
    "    for subfolder, middle_folder in subfolders.items():\n",
    "        middle_folder_path = os.path.join(base_folder, subfolder, middle_folder)\n",
    "        os.makedirs(middle_folder_path, exist_ok=True)\n",
    "\n",
    "        for sub_subfolder in sub_subfolders:\n",
    "            sub_subfolder_path = os.path.join(middle_folder_path, sub_subfolder)\n",
    "            os.makedirs(sub_subfolder_path, exist_ok=True)\n",
    "\n",
    "            if sub_subfolder == \"images\":\n",
    "                for img_subfolder in image_subfolders:\n",
    "                    img_subfolder_path = os.path.join(sub_subfolder_path, img_subfolder)\n",
    "                    os.makedirs(img_subfolder_path, exist_ok=True)\n",
    "\n",
    "create_dataset_structure(\"dataset/reduce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce data \n",
    "\n",
    "We try to reduce the data to (20000, 1000, 1000) for (train, val, test) of each folder. The reduced data saved to `./dataset/reduce/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 20000\n",
    "VAL_SIZE = 1000\n",
    "TEST_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_path = 'dataset/reduce'\n",
    "os.makedirs(reduce_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folders = ['clsdata(1031)', 'piedata(1008)', 'bardata(1031)']\n",
    "sub_folders = ['annotations', 'images']  \n",
    "image_sub_folders = ['train2019', 'val2019', 'test2019']\n",
    "\n",
    "sub_dir_map = {\n",
    "    main_folders[0]: \"cls\",\n",
    "    main_folders[1]: \"pie\",\n",
    "    main_folders[2]: \"bar\"\n",
    "}\n",
    "\n",
    "for main in main_folders:\n",
    "    parent_dir = os.path.join(reduce_path, main, sub_dir_map[main])\n",
    "\n",
    "    for sub in sub_folders:\n",
    "        sub_dir_path = os.path.join(parent_dir, sub)\n",
    "        os.makedirs(sub_dir_path, exist_ok=True) \n",
    "\n",
    "        if sub == \"images\":\n",
    "            for image_sub in image_sub_folders:\n",
    "                os.makedirs(os.path.join(sub_dir_path, image_sub), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a helper function to reduce data in bar, pie, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_annotation(data, size):\n",
    "    \"\"\" \n",
    "    Reduces the annotation data to the given size\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data to be reduced\n",
    "        size (int): The size to reduce the data to \n",
    "\n",
    "    Returns:\n",
    "        dict: The reduced data\n",
    "    \"\"\"\n",
    "    annotations_df = pd.DataFrame(data['annotations'])\n",
    "    images_df = pd.DataFrame(data['images'])    \n",
    "    \n",
    "    # Take the first size number of images\n",
    "    ids1 = images_df['id']\n",
    "    ids2 = annotations_df['image_id']\n",
    "\n",
    "    # Intersection of the two sets\n",
    "    ids = ids1[ids1.isin(ids2)]\n",
    "    ids = ids.sort_values()\n",
    "    ids = ids[:size]\n",
    "\n",
    "    # Filter the annotations based on the image ids\n",
    "    reduced_annotations = annotations_df[annotations_df['image_id'].isin(ids)]\n",
    "    reduced_images = images_df[images_df['id'].isin(ids)]\n",
    "    \n",
    "    data['images'] = json.loads(reduced_images.to_json(orient=\"records\"))\n",
    "    data['annotations'] = json.loads(reduced_annotations.to_json(orient=\"records\"))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another helper function to reduce data in cls (we can use the previous function but it just take 10000 bar data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_annotation_cls(data, size, RATES = [0.33, 0.33, 0.34]):\n",
    "    \"\"\"\n",
    "    Reduces the cls data to the given size \n",
    "    Keep the rate of 0 1 and 2 the same (0.33, 0.33, 0.34)\n",
    "    \n",
    "    Args:\n",
    "        data (dict): The data to be reduced\n",
    "        size (int): The size to reduce the data to \n",
    "\n",
    "    Returns:\n",
    "        dict: The reduced data\n",
    "    \"\"\"\n",
    "\n",
    "    annotations_df = pd.DataFrame(data['annotations'])\n",
    "    images_df = pd.DataFrame(data['images'])    \n",
    "\n",
    "    # Take each class index for images and annotations\n",
    "    cls0_image_ids = images_df[images_df['data_type'] == 0]['id']\n",
    "    cls1_image_ids = images_df[images_df['data_type'] == 1]['id']\n",
    "    cls2_image_ids = images_df[images_df['data_type'] == 2]['id']\n",
    "\n",
    "    cls0_annotation_ids = annotations_df[annotations_df['category_id'] == 0]['image_id']\n",
    "    cls1_annotation_ids = annotations_df[annotations_df['category_id'] == 1]['image_id']\n",
    "    cls2_annotation_ids = annotations_df[annotations_df['category_id'] == 2]['image_id']\n",
    "\n",
    "    # Take the intersection of image ids and annotation ids\n",
    "    cls0_ids = cls0_image_ids[cls0_image_ids.isin(cls0_annotation_ids)]\n",
    "    cls1_ids = cls1_image_ids[cls1_image_ids.isin(cls1_annotation_ids)]\n",
    "    cls2_ids = cls2_image_ids[cls2_image_ids.isin(cls2_annotation_ids)]\n",
    "\n",
    "    # Take the first size * RATE of the ids\n",
    "    reduced_cls0_ids = cls0_ids[:int(size * RATES[0])]\n",
    "    reduced_cls1_ids = cls1_ids[:int(size * RATES[1])]\n",
    "    reduced_cls2_ids = cls2_ids[:int(size * RATES[2])]\n",
    "\n",
    "    ids = pd.concat([reduced_cls0_ids, reduced_cls1_ids, reduced_cls2_ids])\n",
    "\n",
    "    # Filter the annotations based on the image ids\n",
    "    reduced_annotations = annotations_df[annotations_df['image_id'].isin(ids)]\n",
    "    reduced_images = images_df[images_df['id'].isin(ids)]\n",
    "\n",
    "    data['images'] = json.loads(reduced_images.to_json(orient=\"records\"))\n",
    "    \n",
    "    data['annotations'] = json.loads(reduced_annotations.to_json(orient=\"records\"))\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset/raw'\n",
    "output_path = 'dataset/reduce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 2s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for folder in os.listdir(data_path):\n",
    "    main_folder_path = os.path.join(data_path, folder)\n",
    "\n",
    "    # Check if it is a folder\n",
    "    if not os.path.isdir(main_folder_path):\n",
    "        continue\n",
    "\n",
    "    sub_folders = os.listdir(main_folder_path)\n",
    "\n",
    "    sub_folder = sub_folders[0] \n",
    "    sub_folder_path = os.path.join(main_folder_path, sub_folder)\n",
    "    annotations_path = os.path.join(sub_folder_path, \"annotations\")\n",
    "\n",
    "\n",
    "    output_annotations_path = os.path.join(output_path, folder, sub_folder, \"annotations\")\n",
    "\n",
    "    for file_name in os.listdir(annotations_path):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            input_file = os.path.join(annotations_path, file_name)\n",
    "            output_file = os.path.join(output_annotations_path, file_name)\n",
    "\n",
    "            with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            if \"train\" in file_name:\n",
    "                size = TRAIN_SIZE\n",
    "            elif \"val\" in file_name:\n",
    "                size = VAL_SIZE\n",
    "            elif \"test\" in file_name:\n",
    "                size = TEST_SIZE\n",
    "\n",
    "            # Check startwith cls\n",
    "            if folder.startswith(\"cls\"):\n",
    "                reduced_json = reduced_annotation_cls(data, size)\n",
    "            else:\n",
    "                reduced_json = reduced_annotation(data, size)\n",
    "\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(reduced_json, f, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images(data, type, split):\n",
    "    \"\"\"\n",
    "    Copies the images from the original dataset to the reduced dataset\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data containing the image filenames\n",
    "        type (str): The type of the data (bar, pie, line, cls)\n",
    "        split (str): The split of the data (train, val, test)\n",
    "    \"\"\"\n",
    "    image_filenames = {img[\"file_name\"] for img in data.get(\"images\", [])}\n",
    "\n",
    "    if type == 'pie':\n",
    "        if split == 'train':\n",
    "            src_path = 'dataset/raw/piedata(1008)/pie/images/train2019'\n",
    "            copy_path = 'dataset/reduce/piedata(1008)/pie/images/train2019'\n",
    "        elif split == 'val':\n",
    "            src_path = 'dataset/raw/piedata(1008)/pie/images/val2019'\n",
    "            copy_path = 'dataset/reduce/piedata(1008)/pie/images/val2019'\n",
    "        elif split == 'test':\n",
    "            src_path = 'dataset/raw/piedata(1008)/pie/images/test2019'\n",
    "            copy_path = 'dataset/reduce/piedata(1008)/pie/images/test2019'\n",
    "\n",
    "    elif type == 'cls':\n",
    "        if split == 'train':\n",
    "            src_path = 'dataset/raw/clsdata(1031)/cls/images/train2019'\n",
    "            copy_path = 'dataset/reduce/clsdata(1031)/cls/images/train2019'\n",
    "        elif split == 'val':\n",
    "            src_path = 'dataset/raw/clsdata(1031)/cls/images/val2019'\n",
    "            copy_path = 'dataset/reduce/clsdata(1031)/cls/images/val2019'\n",
    "        elif split == 'test':\n",
    "            src_path = 'dataset/raw/clsdata(1031)/cls/images/test2019'\n",
    "            copy_path = 'dataset/reduce/clsdata(1031)/cls/images/test2019'\n",
    "\n",
    "    elif type == 'bar':\n",
    "        if split == 'train':\n",
    "            src_path = 'dataset/raw/bardata(1031)/bar/images/train2019'\n",
    "            copy_path = 'dataset/reduce/bardata(1031)/bar/images/train2019'\n",
    "        elif split == 'val':\n",
    "            src_path = 'dataset/raw/bardata(1031)/bar/images/val2019'\n",
    "            copy_path = 'dataset/reduce/bardata(1031)/bar/images/val2019'\n",
    "        elif split == 'test':\n",
    "            src_path = 'dataset/raw/bardata(1031)/bar/images/test2019'\n",
    "            copy_path = 'dataset/reduce/bardata(1031)/bar/images/test2019'\n",
    "\n",
    "    copy_image_path = None  \n",
    "    copied_count = 0\n",
    "\n",
    "    for image_name in image_filenames:\n",
    "        src_image_path = os.path.join(src_path, image_name)\n",
    "        copy_image_path = os.path.join(copy_path, image_name)\n",
    "\n",
    "        if os.path.exists(src_image_path):  \n",
    "            shutil.copy2(src_image_path, copy_image_path)\n",
    "            copied_count += 1\n",
    "        else:\n",
    "            print(f\"Cannot found any images in: {src_image_path}\")\n",
    "\n",
    "    if copied_count > 0:\n",
    "        print(f\"{copied_count}/{len(image_filenames)} images copied to {copy_path}\\n\")\n",
    "    else:\n",
    "        print(f\"No images are copied to {copy_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie\n",
    "with open('dataset/reduce/piedata(1008)/pie/annotations/instancesPie(1008)_train2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    pie_train = json.load(f)\n",
    "\n",
    "with open('dataset/reduce/piedata(1008)/pie/annotations/instancesPie(1008)_val2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    pie_val = json.load(f)\n",
    "\n",
    "with open('dataset/reduce/piedata(1008)/pie/annotations/instancesPie(1008)_test2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    pie_test = json.load(f)\n",
    "    \n",
    "# Cls\n",
    "with open('dataset/reduce/clsdata(1031)/cls/annotations/instancesCls(1031)_train2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    cls_train = json.load(f)\n",
    "\n",
    "with open('dataset/reduce/clsdata(1031)/cls/annotations/instancesCls(1031)_val2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    cls_val = json.load(f)\n",
    "\n",
    "with open('dataset/reduce/clsdata(1031)/cls/annotations/instancesCls(1031)_test2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    cls_test = json.load(f)\n",
    "\n",
    "# Bar\n",
    "with open('dataset/reduce/bardata(1031)/bar/annotations/instancesBar(1031)_train2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    bar_train = json.load(f)\n",
    "\n",
    "with open('dataset/reduce/bardata(1031)/bar/annotations/instancesBar(1031)_val2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    bar_val = json.load(f)\n",
    "\n",
    "with open('dataset/reduce/bardata(1031)/bar/annotations/instancesBar(1031)_test2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    bar_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 images copied to dataset/reduce/piedata(1008)/pie/images/train2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduce/piedata(1008)/pie/images/val2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduce/piedata(1008)/pie/images/test2019\n",
      "\n",
      "20000/20000 images copied to dataset/reduce/clsdata(1031)/cls/images/train2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduce/clsdata(1031)/cls/images/val2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduce/clsdata(1031)/cls/images/test2019\n",
      "\n",
      "20000/20000 images copied to dataset/reduce/bardata(1031)/bar/images/train2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduce/bardata(1031)/bar/images/val2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduce/bardata(1031)/bar/images/test2019\n",
      "\n",
      "CPU times: total: 56.6 s\n",
      "Wall time: 6min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_images(pie_train, 'pie', 'train')\n",
    "copy_images(pie_val, 'pie', 'val')\n",
    "copy_images(pie_test, 'pie', 'test')\n",
    "\n",
    "copy_images(cls_train, 'cls', 'train')\n",
    "copy_images(cls_val, 'cls', 'val')\n",
    "copy_images(cls_test, 'cls', 'test')\n",
    "\n",
    "copy_images(bar_train, 'bar', 'train')\n",
    "copy_images(bar_val, 'bar', 'val')\n",
    "copy_images(bar_test, 'bar', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO to YOLO format\n",
    "\n",
    "Draw a image and it bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_image = pie_val['images'][16]\n",
    "# idx = first_image['id']\n",
    "# file_name = first_image['file_name']\n",
    "# bboxs = [ann for ann in pie_val['annotations'] if ann['image_id'] == idx]\n",
    "\n",
    "# print(f\"Image ID: {idx}\")\n",
    "# print(f\"File Name: {file_name}\")\n",
    "# for i, b in enumerate(bboxs):\n",
    "#     print(f\"Box {i + 1}: {b['bbox']}\")\n",
    "    \n",
    "# plt.figure(figsize=(10, 10))\n",
    "# image = plt.imread(f'dataset/reduce/piedata(1008)/pie/images/val2019/{file_name}')\n",
    "\n",
    "# for bbox in bboxs:\n",
    "#     arc_1_x, arc_1_y, arc_2_x, arc_2_y, center_x, center_y = bbox['bbox']\n",
    "#     plt.plot([arc_1_x, arc_2_x], [arc_1_y, arc_2_y], 'r')\n",
    "#     plt.plot([arc_2_x, center_x], [arc_2_y, center_y], 'r')\n",
    "#     plt.plot([center_x, arc_1_x], [center_y, arc_1_y], 'r')\n",
    "    \n",
    "# plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced_annotation_pie_train = \"./dataset/reduce/piedata(1008)/pie/annotations/instancesPie(1008)_train2019.json\"\n",
    "# reduced_annotation_pie_val = \"./dataset/reduce/piedata(1008)/pie/annotations/instancesPie(1008)_val2019.json\"\n",
    "# reduced_annotation_pie_test = \"./dataset/reduce/piedata(1008)/pie/annotations/instancesPie(1008)_test2019.json\"\n",
    "\n",
    "# reduced_annotation_pieR_train = \"./dataset/reduce/piedata(1008)/pie/annotations/instancesPieR(1008)_test2019.json\"\n",
    "# reduced_annotation_pieR_val = \"./dataset/reduce/piedata(1008)/pie/annotations/instancesPieR(1008)_val2019.json\"\n",
    "# reduced_annotation_pieR_test = \"./dataset/reduce/piedata(1008)/pie/annotations/instancesPieR(1008)_test2019.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie_label_dir = \"./dataset/reduce/piedata(1008)/pie/labels\"\n",
    "# os.makedirs(pie_label_dir, exist_ok=True)\n",
    "\n",
    "# train_label_dir = os.path.join(pie_label_dir, \"train2019\")\n",
    "# val_label_dir = os.path.join(pie_label_dir, \"val2019\")\n",
    "# test_label_dir = os.path.join(pie_label_dir, \"test2019\")\n",
    "# os.makedirs(train_label_dir, exist_ok=True)\n",
    "# os.makedirs(val_label_dir, exist_ok=True)\n",
    "# os.makedirs(test_label_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_label_file(annotation_path, label_dir):\n",
    "#     with open(annotation_path, \"r\") as f:\n",
    "#         data = json.load(f)\n",
    "    \n",
    "#     for img in data[\"images\"]:\n",
    "#         img_id = img[\"id\"]\n",
    "#         img_width, im_height = img[\"width\"], img[\"height\"]\n",
    "#         img_name = img[\"file_name\"]\n",
    "        \n",
    "#         label_path = os.path.join(label_dir, f\"{os.path.splitext(img_name)[0]}.txt\")\n",
    "        \n",
    "#         with open(label_path, 'w') as f:\n",
    "#             for annotation in data[\"annotations\"]:\n",
    "#                 if annotation[\"image_id\"] == img_id:\n",
    "#                     category_id = annotation[\"category_id\"]\n",
    "#                     x1, y1, x2, y2, xc, yc = annotation[\"bbox\"]\n",
    "                    \n",
    "#                     x1 = x1 / img_width\n",
    "#                     y1 = y1 / im_height\n",
    "#                     x2 = x2 / img_width\n",
    "#                     y2 = y2 / im_height\n",
    "#                     xc = xc / img_width\n",
    "#                     yc = yc / im_height\n",
    "                    \n",
    "#                     f.write(f\"{category_id} {x1} {y1} {x2} {y2} {xc} {yc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_label_file(reduced_annotation_pie_train, train_label_dir)\n",
    "# create_label_file(reduced_annotation_pie_val, val_label_dir)\n",
    "# create_label_file(reduced_annotation_pie_test, test_label_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepRule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
